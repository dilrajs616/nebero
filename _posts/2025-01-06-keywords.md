---

layout: default  
title: "Keyword Extraction Process"

---

## Overview

In this section, we detail the **keyword extraction** process used in our automated website categorization pipeline. Keyword extraction is a crucial step in understanding the content of websites by identifying the most relevant words or phrases that represent the main ideas. By extracting keywords, we can effectively analyze and categorize websites based on their textual content.

---

## Types of Keyword Extraction

There are several types of keyword extraction methods, each with its own advantages and use cases. The methods can be broadly classified into **statistical**, **semantic**, and **hybrid** approaches:

### 1. Statistical Keyword Extraction

This method focuses on analyzing the frequency of terms in the text and identifying the most common or significant words based on statistical measures. Some common statistical methods include:

- **Term Frequency (TF)**: Measures how often a word appears in a document.
- **Inverse Document Frequency (IDF)**: Measures the importance of a word across a collection of documents (corpus). Words that appear in many documents are considered less important.

### 2. Semantic Keyword Extraction

This approach focuses on extracting keywords based on the meaning or context of words, often using more advanced machine learning or deep learning techniques. Some examples include:

- **Word Embeddings (e.g., Word2Vec, GloVe)**: Represent words as vectors in a high-dimensional space, capturing the semantic meaning of words based on their context in a corpus.
- **Transformer-based Models (e.g., BERT)**: Use deep learning models to understand the context and relationships between words in a sentence, providing more accurate keyword extraction.

### 3. Hybrid Keyword Extraction

Hybrid methods combine statistical and semantic approaches to achieve a balance between speed and accuracy. These methods may use statistical techniques like TF-IDF for initial keyword selection and then apply semantic analysis for deeper understanding.

---

## Chosen Method: TF-IDF

In our case, we decided to use the **Term Frequency-Inverse Document Frequency (TF-IDF)** method for keyword extraction, as it provides a good balance between efficiency and relevance, particularly for our goal of categorizing websites based on their textual content.

### Why TF-IDF?

We initially explored advanced models like **BERT-based** keyword extraction, which leverages deep learning to understand the context of words. However, this approach proved to be resource-intensive, requiring large models and substantial computational power. Since our primary focus was efficiency and scalability in extracting relevant keywords from hundreds of thousands of websites, **TF-IDF** emerged as a simpler and more effective solution.

TF-IDF provides an easy way to extract keywords without needing to rely on complex models, and it has the following advantages:
- **Efficiency**: TF-IDF is computationally less expensive compared to BERT-based models.
- **Simplicity**: It is straightforward to implement and interpret.
- **Scalability**: It scales well to large datasets, making it ideal for our use case of scraping hundreds of thousands of websites.

---

## Converting Data into Numerical Form for TF-IDF

The TF-IDF algorithm operates on numerical data, so textual content must be converted into a numerical format before applying the algorithm. This process involves several intermediate steps to clean and prepare the data for analysis:

1. **Tokenization**: Breaking the text into individual words (tokens).
2. **Stop-word Removal**: Eliminating common words (e.g., "the", "is", "in") that do not carry significant meaning in the context of keyword extraction.
3. **Lowercasing**: Converting all text to lowercase to ensure consistency, as "Website" and "website" should be considered the same word.
4. **Punctuation and Special Character Removal**: Removing any punctuation, special characters, or numbers from the text, as they typically do not contribute to keyword extraction.
5. **Stemming/Lemmatization**: Reducing words to their base form (e.g., "running" becomes "run") to avoid treating different forms of the same word as separate tokens.

After these preprocessing steps, the text is ready for vectorization, which converts the cleaned text into numerical data that can be processed by the TF-IDF algorithm.

---

## How TF-IDF Works

The TF-IDF method combines two important statistics:

1. **Term Frequency (TF)**: This measures how often a word appears in a document. The more frequently a word appears in a document, the higher its term frequency.

   \[
   \text{TF}(t) = \frac{\text{Number of times term t appears in the document}}{\text{Total number of terms in the document}}
   \]

   Example:  
   Consider a document containing the sentence "AI models are very powerful".  
   - "AI" appears once, so TF("AI") = 1/5 = 0.2  
   - "models" appears once, so TF("models") = 1/5 = 0.2  
   - "are" appears once, so TF("are") = 1/5 = 0.2  
   - "very" appears once, so TF("very") = 1/5 = 0.2  
   - "powerful" appears once, so TF("powerful") = 1/5 = 0.2

2. **Inverse Document Frequency (IDF)**: This measures how important a word is across all documents in the corpus. Words that appear frequently in many documents are less informative and thus assigned a lower IDF score.

   \[
   \text{IDF}(t) = \log\left(\frac{\text{Total number of documents}}{\text{Number of documents containing term t}}\right)
   \]

   Example:  
   In a corpus of 100 documents, if the term "AI" appears in 50 of them, the IDF of "AI" is:

   \[
   \text{IDF}(\text{AI}) = \log\left(\frac{100}{50}\right) = \log(2) = 0.3010
   \]

### TF-IDF Calculation

The **TF-IDF score** of a term is simply the product of the **TF** and **IDF** scores:

\[
\text{TF-IDF}(t) = \text{TF}(t) \times \text{IDF}(t)
\]

Example:  
For the term "AI" in the document mentioned earlier, we calculate:

\[
\text{TF-IDF}(\text{AI}) = 0.2 \times 0.3010 = 0.0602
\]

The TF-IDF scores for other words in the document can be similarly calculated.

---

## Steps Involved in Keyword Extraction using TF-IDF

1. **Data Preprocessing**: Clean the scraped website content by removing stop words, special characters, punctuation, and performing tokenization.
2. **Vectorization**: Convert the cleaned text into a **TF-IDF matrix**, where each row represents a document (website), and each column represents a unique term in the corpus.
3. **Ranking Keywords**: For each website, sort the terms based on their **TF-IDF** scores and select the top-ranked terms as the most significant keywords.
4. **Keyword Selection**: Depending on the number of keywords you want to extract, you can set a threshold (e.g., select the top 10 or top 20 keywords for each website).

---

## Example Workflow

### Input:

Imagine we have a website content like this:

**"Artificial intelligence (AI) is transforming industries. AI models are becoming very powerful and impactful."**

After preprocessing (tokenization, stop-word removal, lowercasing, etc.), the cleaned text might look like:

**["artificial", "intelligence", "ai", "transforming", "industries", "models", "becoming", "powerful", "impactful"]**

### Vectorization:

The TF-IDF vectorizer creates a matrix where each word's importance (TF-IDF score) in the entire corpus is calculated.

For example, for a smaller corpus with three documents (websites):

1. "AI models are powerful"
2. "AI in healthcare"
3. "AI models for industry"

The TF-IDF matrix might look like this:

| Term       | Doc 1 | Doc 2 | Doc 3 |
|------------|-------|-------|-------|
| AI         | 0.5   | 0.3   | 0.4   |
| models     | 0.7   | 0.0   | 0.6   |
| powerful   | 0.5   | 0.0   | 0.0   |
| healthcare | 0.0   | 0.7   | 0.0   |
| industry   | 0.0   | 0.0   | 0.7   |

### Keyword Ranking:

Once the TF-IDF scores are calculated, the top-ranked keywords for each document (website) can be selected. For instance, if the TF-IDF scores for a website's content are as follows:

- **"AI"**: 0.5
- **"models"**: 0.7
- **"powerful"**: 0.5

The top keywords extracted would be "models", "AI", and "powerful".

---

## Conclusion

The **TF-IDF** method is a highly effective and efficient technique for extracting relevant keywords from website content. By converting the raw text into numerical form and applying TF-IDF, we can identify the most important words that describe the content of a website. Despite exploring more advanced methods like **BERT-based keyword extraction**, TF-IDF was chosen for its simplicity, scalability, and effectiveness in our projectâ€™s requirements. The process involves several intermediate steps like **stop-word removal**, **tokenization**, and **lemmatization**, which help clean and preprocess the data to ensure accurate and meaningful keyword extraction.

