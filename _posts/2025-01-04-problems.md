---
layout: default
title: "Problems in Web Scraping"
---

During the web scraping process, several challenges were encountered related to **bandwidth**, **memory usage**, and **CPU utilization**. These issues affected the efficiency and stability of the scraping process when scraping multiple websites in parallel. Below, we detail these problems and the solutions we implemented to overcome them.

## 1. Bandwidth Issues

When attempting to scrape multiple websites simultaneously using Playwright by opening multiple browser tabs in parallel, we encountered significant bandwidth limitations. As a result, websites often failed to load, resulting in **timeouts**. This was due to the **insufficient available bandwidth** to handle the concurrent requests from multiple tabs.

### Key Challenges:
- **Multiple Concurrent Requests**: Opening several tabs to scrape websites in parallel caused an overload of the available bandwidth.
- **Time-outs**: Because of the bandwidth limitation, many websites would not load within the expected time frame, leading to timeouts.

### Solution:
To resolve this issue, we needed a more robust infrastructure with higher bandwidth. This led to renting a **server in Singapore** with a **1 GBPS connection**, which provided significantly more bandwidth for handling concurrent requests without timeouts.

## 2. Memory Leaks in Playwright

Another significant problem encountered was related to **memory leaks** in Playwright. When the scraper was run for extended periods, the process would gradually consume more memory. Eventually, this would result in the system running out of memory, causing the scraping process to stop.

### Key Challenges:
- **Memory Accumulation**: Playwright would use more and more memory as the scraping process continued, without releasing it.
- **Process Termination**: The process would eventually stop when the system reached its memory limit.

### Solution:
To address the memory leak issue, we shifted to a more powerful server with **128 GB of RAM**. This allowed us to run the scraping process for longer periods without hitting memory limitations.

## 3. CPU Utilization

The smaller CPU available in the local setup, with only **4 cores**, was insufficient to handle the high load of scraping multiple websites at once. The CPU would get heavily utilized, leading to **slow performance** and further degradation of the scraping process.

### Key Challenges:
- **Limited CPU Power**: With only 4 cores, the CPU struggled to handle multiple scraping tasks simultaneously, resulting in slow speeds.
- **Performance Degradation**: As the number of websites increased, the scraping process became slower and more inefficient.

### Solution:
To overcome this limitation, we rented a server with an **8-core processor**. This significantly boosted the scraping performance, allowing for more parallel tasks and reducing the time required to scrape websites.

---

## Network Performance Difference: WiFi/Ethernet vs. Rented Server

Despite having a **1 GBPS connection** from the service provider, we noticed a significant difference in network performance when using **WiFi** or **Ethernet** compared to the **rented server**. On WiFi/Ethernet, the network speed did not fully utilize the 1 GBPS connection, while the rented server was able to achieve the full 1 GBPS speed.

### Explanation:
- **WiFi vs. Ethernet**: WiFi connections typically have higher latency and more variable speeds, especially if multiple devices are connected or if the signal strength is weak. Ethernet, while more stable than WiFi, can still be impacted by network congestion, suboptimal cables, or hardware limitations.
- **Rented Server**: The rented server, however, had a dedicated and optimized **1 GBPS connection** that was consistent and designed for high-performance tasks like web scraping. This allows for stable and high-speed data transfer without the variability seen in home or office network environments.

Thus, even though both the WiFi/Ethernet connection and the server had a **1 GBPS connection** from the service provider, the server's infrastructure was far better optimized for consistently achieving that speed.
